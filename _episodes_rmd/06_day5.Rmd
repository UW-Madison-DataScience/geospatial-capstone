---
title: "Day 6"
teaching: 0
exercises: 0
questions:
- "change"
objectives:
- "change"
keypoints:
- "First key point. Brief Answer to questions. (FIXME)"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#source("../bin/chunk-options.R")
#knitr_fig_path("03-")
```

# Outline
- Addressing Minute questions (10-15 min)
- Revisit your spatial question
- Add point data from a non-spatial CSV file (thoughts:Use csv to add in points for each county (we would need to create these points ahead) - these points could be precipitation collection spots, weather forecasting locations, centroids?, major cities?)
- Crop raster data with vector data and output summary information (thoughts:Take raster data and crop with vector or point and vector and summarize stats.  Question for them to solve.  Mean temp diff for two cities?  Max precipitation of every county?)
- Thing to highlight: Using last question to also talk about pros/cons of raster vector data with answering questions like these
- Addressing final questions (10-15 min)


# Revisit your spatial question

On day 1 we brainstormed questions you could ask with geospatial data. You thought about questions you can answer with rater data, and separately, questions you could answer with vector data. Through this workshop you have practiced worked with spatial data and have the tools to answer your questions.

In this final day we will implement tools you learned for combining rater and vector data and the types of questions you can answer when doing so.

These questions may look like the following:
+ where does something occur?
+ how does something change across space or time?
+ what are the differences between locations?

Examples of questions are:
+ What county has the highest recorded precipitation?
+ Has mean annual temperature increased in the state?
+ How does the precipitation vary between Milwaukee and Madison?

For this final day, you may work on your own capstone question using your data. If you do not have your own question or data, you can follow along with the example question for today.

# Day 5 capstone sample question
Does it get hotter in Milwaukee or Madison?


# Import your spatial data
Start by importing your spatial data. Remember, for raster data, you will likely use functions in the `raster` package. For vector data, you will use functions in the `sf` package. In addition, because we will want to visualize our data, we will use the plotting package `ggplot2`.

```{r load package}

library(raster)
library(sf)
library(ggplot2)

```


## Raster data
For this example, we will use the World Climate dataset. You can either download this dataset from the website. Or you can access the dataset using the R package.

If you need a refresher on how to do this, look at this website: https://www.gis-blog.com/r-raster-data-acquisition/ 

The goal of this section is to have your raster data as a 'Formal class RasterLayer' in your Global Environment

```{r load-raster-data}

# get worldclim data, variable "bio" with a 10 degree resolution
# this line is downloading data
# if you selected a resolution higher than 10 (with a res of 0.5,2.5, or 5) it may take a while to download
worldClim_bio_global <- getData("worldclim", var="bio", res=10)

# use only the bio5 variable (BIO5 = Max Temperature of Warmest Month)
plot(worldClim_bio_global$bio5)

maxTemp_global <- worldClim_bio_global$bio5


```


## Vector data
For this example, we will use the Natual Earth Populated Places dataset. You can access these data from the Natural Earth package, or download the data from the website.

The goal of this section is to have a simple feature ('sf') data frame type of object in your Global Environment.


```{r load-city-point-data}

# import point data from a csv file
WIcities <- read.csv("data/ne_10m_populated_places_Wisconsin.csv")

# check out the data
colnames(WIcities)

```

Recall from your lesson how to import point data and convert it to a spatial data layer in R.

When looking at the column names we see that there is a lot of data! To convert to a spatial points data layer, we need to know information about the coordinate system and the coordinates for each point.

The column names 'LATITUDE' and 'LONGITUDE' have what we need! 

Explain how we know about the coordinate system because of these coordinates.
Reference this website: https://spatialreference.org/ref/epsg/wgs-84/ 

> ## Solution: Load .csv point data?
>
> Text here describing what's in this box
>
>
> > ## Solution
> >
> > ```{r, echo=FALSE}
> > paste("This", "new", "template", "looks", "good")
> > ```
> {: .solution}

```{r convert-to-points}

# convert data framem to sf type of object by specifying coordinates (as xy) and the projection as a crs
WIcities_points <- st_as_sf(WIcities, coords=c('LONGITUDE','LATITUDE'), crs=crs(maxTemp_global))

# check class of object - should be "sf" data frame
class(WIcities_points)


```

A critical part of working with raster and vector data together is that the dataasets are in the same coordinate system. 

Does it make sense? Are they the same?

```{r check-coordinate-systems}

crs(maxTemp_global)
crs(WIcities_points)

crs(maxTemp_global)
crs(WIcities_points)

extent(maxTemp_global)
extent(WIcities_points)

res(maxTemp_global)

```



Finally, let's subset our spatial data to only include the city points we are interested in. For the sample dataset, we are going to subset the data to only include the cities of Madison and Milwaukee.

If you are using your own data, you may or may not need to do this set.

```{r subset-vector-data}

WIcities_points$NAME

MM_points <- WIcities_points[WIcities_points$NAME=='Madison'|WIcities_points$NAME=='Milwaukee',]

```

# Crop raster data by vector locations

UPDATE. Langugae about cropping. Why do this. We will crop to WI cities, then plot to see the data better.

```{r crop-raster-by-vector}

maxTemp_WI <- crop(x = maxTemp_global, y = extent(WIcities_points),snap="out")
maxTemp_WI_df <- as.data.frame(maxTemp_WI, xy=T)

ggplot() +
  geom_raster(data = maxTemp_WI_df,aes(x = x, y = y, fill = bio5)) + 
  geom_sf(data = MM_points,color="yellow",size=5) + 
  coord_sf()

```


# Summarize raster data by vector locations
Now that we have our raster layer that contains the data we want to summarize, and the vector data that contains the locations indicating where we want to summarize the data, we can now put them together.

If you are working with your own data, ask yourself:
+ How do I want to summarize the data? For example, do I want a single mean value? A maximum? A distribution of all values?
+ What is the area I want to summarize? If it's a point, do you want a certain distance around the point? Or, if it's an area, you will include all of the raster values within that area.

One thing you'll need to consider is the converstion from degrees to meters. The conversions depends on where you are on the globe. For example, at the equator, 1 degree is 111 km. This distance decreases as you move closer to the poles. Here is an article: https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps?qt-news_science_products=0#qt-news_science_products 

```{r extract-raster-by-vector}

# I'm exepcting a distibution but am getting a single value
# does it have to do with the resolution and the buffer size?
df_maxTemp_MM <- as.data.frame(extract(x=maxTemp_global,df=TRUE,
                           y=MM_points,
                           buffer=50000))

# clean up data frame because we want to give IDs names and convert the temperature data
df_maxTemp_MM$ID <- as.factor(df_maxTemp_MM$ID)
levels(df_maxTemp_MM$ID) = levels(as.factor(MM_points$NAME))

df_maxTemp_MM$bio5 <- df_maxTemp_MM$bio5/10

# plot data
# can make it prettier 
ggplot(data = df_maxTemp_MM, aes(x = bio5,fill=ID)) + 
  geom_histogram() +
  ggtitle("Histogram of maximum temperatures within 50 km of the city") +
  xlab("Maximum temperature (C)") + 
  ylab("Frequency of Pixels")

```



